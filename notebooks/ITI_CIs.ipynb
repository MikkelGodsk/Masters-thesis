{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "n_jobs = 1   # Remember to set `parameters` tag!\n",
    "dtu_hpc = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at DTU HPC\n"
     ]
    }
   ],
   "source": [
    "if (not dtu_hpc) or (dtu_hpc == \"false\"):\n",
    "  from google.colab import drive, userdata\n",
    "  import os\n",
    "  print(\"Running on Google Colab\")\n",
    "  drive.mount('/content/drive')\n",
    "  drive_dir = '/content/drive/My Drive/'\n",
    "  data_dir = os.path.join(drive_dir, 'ITI-datasets')\n",
    "  cache_dir = os.path.join(drive_dir, 'model_cache')\n",
    "  !pip install -q seaborn\n",
    "  disable_pbar = False\n",
    "\n",
    "else:\n",
    "  import os\n",
    "  print(\"Running at DTU HPC\")\n",
    "  drive_dir = '/work3/s184399/msc'\n",
    "  data_dir = os.path.join(drive_dir, 'ITI-datasets')\n",
    "  cache_dir = os.path.join(drive_dir, \"cache_dir\", \"huggingface\")\n",
    "  disable_pbar = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test: Test the bias on some whack distribution, possibly using the Dirichlet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def bootstrap_CI(p, alpha=0.05, k=2000):\n",
    "  \"\"\"\n",
    "    Computes the confidence interval of the mean using bootstrapping.\n",
    "    Here the confidence interval is the 100*(1-alpha) central CI, from percentile 100*(alpha/2) to 100*(1-alpha/2) rounded to broadest interval when picking the indices.\n",
    "    Line Clemmensen suggests picking k (number of repeats) to 1000 or 2000 for this tasks, so I do this.\n",
    "  \"\"\"\n",
    "  assert isinstance(p, np.ndarray)\n",
    "  assert p.ndim == 1\n",
    "  N = len(p)\n",
    "  bootstraps = np.random.choice(p, (k,N), replace=True)\n",
    "  ci_lower = alpha/2.\n",
    "  ci_upper = 1.-(alpha/2.)\n",
    "  idxs = [\n",
    "    int(np.floor(k*ci_lower)),\n",
    "    int(np.ceil(k*ci_upper))\n",
    "  ]\n",
    "  CI = np.sort(np.mean(bootstraps, axis=-1))[idxs]     # Sorts lowest to highest\n",
    "  assert CI[0] <= CI[1]  # To be on the safe side...\n",
    "  CI = f\"[{(CI[0]*100):.2f}%, {(CI[1]*100):.2f}%]\"\n",
    "  return CI, N    # Returns CI and support (N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming patterns (titles in data_dir)\n",
    "# f\"is_correct_{model_name_str}_ITI_truthful_qa_par3.npz\"\n",
    "# f\"is_correct_{model_name_str}_ITI_truthful_qa_{ood_test}.npz\"\n",
    "# f\"is_correct_{model_name_str}_Base_truthful_qa_par3.npz\"\n",
    "# f\"is_correct_{model_name_str}_Base_truthful_qa_{ood_test}.npz\"\n",
    "files = os.listdir(data_dir)\n",
    "files = list(filter(lambda x: x.startswith('is_correct') and x.endswith('.npz'), files))\n",
    "\n",
    "dataset_names = ['par3', 'common_claim_true_false', 'counterfact_true_false', 'cities', 'neg_cities', 'politicians']\n",
    "#model_names = ['Llama-2-7b-chat-hf', 'Llama-2-7b-hf', 'Meta-Llama-3-8B', 'Meta-Llama-3-8B-Instruct', 'Mistral-7B-Instruct-v0.2', 'Mistral-7B-Instruct-v0.3', 'Mistral-7B-v0.3', 'Mixtral-8x7B-v0.1', 'Mixtral-8x7B-Instruct-v0.1', 'opt-2.7b', 'opt-125m', 'opt-350m', 'Phi-3-mini-4k-instruct'] \n",
    "model_names = ['Llama-2-7b-hf', 'Meta-Llama-3-8B', 'Meta-Llama-3-8B-Instruct', 'Mistral-7B-Instruct-v0.2', 'Mistral-7B-Instruct-v0.3', 'Mistral-7B-v0.3', 'Mixtral-8x7B-v0.1', 'opt-2.7b', 'opt-125m', 'opt-350m', 'Phi-3-mini-4k-instruct'] \n",
    "\n",
    "\n",
    "# Check that we have all files...\n",
    "missing_files = []\n",
    "for d_name in dataset_names:\n",
    "    for m_name in model_names:\n",
    "        if not f\"is_correct_{m_name}_ITI_truthful_qa_{d_name}.npz\" in files:\n",
    "            missing_files.append(f\"is_correct_{m_name}_ITI_truthful_qa_{d_name}.npz\")\n",
    "        if not f\"is_correct_{m_name}_Base_truthful_qa_{d_name}.npz\" in files:\n",
    "            missing_files.append(f\"is_correct_{m_name}_Base_truthful_qa_{d_name}.npz\")\n",
    "assert len(missing_files) == 0, f\"Missing files: {missing_files}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual performance CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      " & par3 & common_claim_true_false & counterfact_true_false & cities & neg_cities & politicians \\\\\n",
      "\\midrule\n",
      "Llama-2-7b-hf ITI & [46.15%, 55.95%] & [53.69%, 55.72%] & [85.50%, 88.54%] & [97.26%, 98.65%] & [2.26%, 4.35%] & [60.79%, 62.71%] \\\\\n",
      "Llama-2-7b-hf Base & [31.50%, 40.85%] & [57.21%, 59.46%] & [84.84%, 87.87%] & [97.96%, 99.13%] & [2.87%, 5.00%] & [62.00%, 63.92%] \\\\\n",
      "Meta-Llama-3-8B ITI & [48.43%, 59.77%] & [49.02%, 50.10%] & [50.53%, 55.80%] & [54.67%, 60.80%] & [39.37%, 45.94%] & [44.58%, 46.73%] \\\\\n",
      "Meta-Llama-3-8B Base & [32.59%, 42.15%] & [47.98%, 53.85%] & [76.33%, 80.62%] & [92.99%, 95.49%] & [8.64%, 12.12%] & [58.45%, 60.36%] \\\\\n",
      "Meta-Llama-3-8B-Instruct ITI & [52.83%, 63.57%] & [47.10%, 53.30%] & [53.76%, 58.98%] & [57.38%, 63.38%] & [35.52%, 41.38%] & [47.14%, 49.31%] \\\\\n",
      "Meta-Llama-3-8B-Instruct Base & [44.61%, 54.88%] & [53.67%, 59.20%] & [77.66%, 81.76%] & [83.90%, 87.98%] & [9.46%, 13.18%] & [56.93%, 58.87%] \\\\\n",
      "Mistral-7B-Instruct-v0.2 ITI & [55.62%, 66.20%] & [78.16%, 82.63%] & [84.29%, 87.75%] & [99.45%, 99.79%] & [8.58%, 12.09%] & [58.76%, 60.73%] \\\\\n",
      "Mistral-7B-Instruct-v0.2 Base & [58.48%, 69.19%] & [78.53%, 83.17%] & [84.46%, 87.99%] & [99.51%, 99.81%] & [7.30%, 10.47%] & [58.29%, 60.32%] \\\\\n",
      "Mistral-7B-Instruct-v0.3 ITI & [51.07%, 61.59%] & [65.93%, 71.14%] & [88.40%, 91.47%] & [99.76%, 99.89%] & [1.74%, 3.21%] & [62.16%, 64.10%] \\\\\n",
      "Mistral-7B-Instruct-v0.3 Base & [53.96%, 64.51%] & [75.28%, 79.73%] & [88.29%, 91.25%] & [99.77%, 99.90%] & [1.18%, 2.40%] & [61.85%, 63.76%] \\\\\n",
      "Mistral-7B-v0.3 ITI & [50.93%, 61.81%] & [47.32%, 53.25%] & [47.51%, 52.10%] & [52.56%, 57.87%] & [42.19%, 47.33%] & [41.02%, 43.29%] \\\\\n",
      "Mistral-7B-v0.3 Base & [35.57%, 45.25%] & [59.49%, 62.22%] & [84.64%, 87.80%] & [99.29%, 99.71%] & [1.64%, 2.67%] & [62.08%, 63.94%] \\\\\n",
      "Mixtral-8x7B-v0.1 ITI & [48.59%, 59.71%] & [47.41%, 53.08%] & [51.69%, 56.28%] & [53.96%, 59.33%] & [40.85%, 46.42%] & [44.43%, 46.65%] \\\\\n",
      "Mixtral-8x7B-v0.1 Base & [38.41%, 47.87%] & [61.09%, 64.70%] & [89.24%, 91.97%] & [98.96%, 99.48%] & [4.35%, 6.45%] & [64.33%, 66.11%] \\\\\n",
      "opt-2.7b ITI & [42.93%, 53.80%] & [47.74%, 52.66%] & [48.91%, 54.26%] & [51.73%, 57.86%] & [42.45%, 48.31%] & [45.72%, 47.93%] \\\\\n",
      "opt-2.7b Base & [31.32%, 40.91%] & [48.67%, 52.60%] & [67.51%, 71.85%] & [86.62%, 90.39%] & [11.65%, 15.39%] & [57.56%, 59.54%] \\\\\n",
      "opt-125m ITI & [41.40%, 51.91%] & [48.96%, 50.92%] & [47.02%, 52.28%] & [50.88%, 56.67%] & [43.20%, 49.07%] & [43.35%, 45.56%] \\\\\n",
      "opt-125m Base & [33.35%, 43.67%] & [47.12%, 52.63%] & [58.10%, 62.68%] & [74.08%, 78.97%] & [22.57%, 27.46%] & [53.02%, 55.18%] \\\\\n",
      "opt-350m ITI & [43.34%, 54.37%] & [47.39%, 52.62%] & [47.12%, 53.19%] & [50.52%, 57.19%] & [43.02%, 49.66%] & [41.25%, 43.47%] \\\\\n",
      "opt-350m Base & [36.46%, 46.75%] & [49.87%, 50.91%] & [61.71%, 66.11%] & [77.95%, 82.48%] & [17.84%, 22.46%] & [54.25%, 56.44%] \\\\\n",
      "Phi-3-mini-4k-instruct ITI & [48.88%, 59.79%] & [47.43%, 53.52%] & [60.70%, 65.71%] & [66.06%, 71.62%] & [28.85%, 34.64%] & [48.45%, 50.71%] \\\\\n",
      "Phi-3-mini-4k-instruct Base & [52.46%, 63.06%] & [74.13%, 77.95%] & [81.62%, 85.20%] & [93.94%, 96.11%] & [8.91%, 11.90%] & [57.35%, 59.24%] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc_performance_df = pd.DataFrame(columns=dataset_names)\n",
    "# Sorry, but no baseline computation in this one (for now at least)...\n",
    "for m_name in model_names:\n",
    "    for version in ['ITI', 'Base']:\n",
    "        row = {}\n",
    "        for d_name in dataset_names:\n",
    "            file_name = f\"is_correct_{m_name}_{version}_truthful_qa_{d_name}.npz\"\n",
    "            data = np.load(os.path.join(data_dir, file_name))\n",
    "            p = data['is_correct']\n",
    "            CI, N = bootstrap_CI(p)\n",
    "            row[d_name] = CI\n",
    "        mc_performance_df.loc[f\"{m_name} {version}\"] = row\n",
    "\n",
    "print(mc_performance_df.to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par3</th>\n",
       "      <th>common_claim_true_false</th>\n",
       "      <th>counterfact_true_false</th>\n",
       "      <th>cities</th>\n",
       "      <th>neg_cities</th>\n",
       "      <th>politicians</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-2-7b-hf ITI</th>\n",
       "      <td>[46.15%, 55.95%]</td>\n",
       "      <td>[53.69%, 55.72%]</td>\n",
       "      <td>[85.50%, 88.54%]</td>\n",
       "      <td>[97.26%, 98.65%]</td>\n",
       "      <td>[2.26%, 4.35%]</td>\n",
       "      <td>[60.79%, 62.71%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-2-7b-hf Base</th>\n",
       "      <td>[31.50%, 40.85%]</td>\n",
       "      <td>[57.21%, 59.46%]</td>\n",
       "      <td>[84.84%, 87.87%]</td>\n",
       "      <td>[97.96%, 99.13%]</td>\n",
       "      <td>[2.87%, 5.00%]</td>\n",
       "      <td>[62.00%, 63.92%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B ITI</th>\n",
       "      <td>[48.43%, 59.77%]</td>\n",
       "      <td>[49.02%, 50.10%]</td>\n",
       "      <td>[50.53%, 55.80%]</td>\n",
       "      <td>[54.67%, 60.80%]</td>\n",
       "      <td>[39.37%, 45.94%]</td>\n",
       "      <td>[44.58%, 46.73%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B Base</th>\n",
       "      <td>[32.59%, 42.15%]</td>\n",
       "      <td>[47.98%, 53.85%]</td>\n",
       "      <td>[76.33%, 80.62%]</td>\n",
       "      <td>[92.99%, 95.49%]</td>\n",
       "      <td>[8.64%, 12.12%]</td>\n",
       "      <td>[58.45%, 60.36%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct ITI</th>\n",
       "      <td>[52.83%, 63.57%]</td>\n",
       "      <td>[47.10%, 53.30%]</td>\n",
       "      <td>[53.76%, 58.98%]</td>\n",
       "      <td>[57.38%, 63.38%]</td>\n",
       "      <td>[35.52%, 41.38%]</td>\n",
       "      <td>[47.14%, 49.31%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct Base</th>\n",
       "      <td>[44.61%, 54.88%]</td>\n",
       "      <td>[53.67%, 59.20%]</td>\n",
       "      <td>[77.66%, 81.76%]</td>\n",
       "      <td>[83.90%, 87.98%]</td>\n",
       "      <td>[9.46%, 13.18%]</td>\n",
       "      <td>[56.93%, 58.87%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2 ITI</th>\n",
       "      <td>[55.62%, 66.20%]</td>\n",
       "      <td>[78.16%, 82.63%]</td>\n",
       "      <td>[84.29%, 87.75%]</td>\n",
       "      <td>[99.45%, 99.79%]</td>\n",
       "      <td>[8.58%, 12.09%]</td>\n",
       "      <td>[58.76%, 60.73%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2 Base</th>\n",
       "      <td>[58.48%, 69.19%]</td>\n",
       "      <td>[78.53%, 83.17%]</td>\n",
       "      <td>[84.46%, 87.99%]</td>\n",
       "      <td>[99.51%, 99.81%]</td>\n",
       "      <td>[7.30%, 10.47%]</td>\n",
       "      <td>[58.29%, 60.32%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.3 ITI</th>\n",
       "      <td>[51.07%, 61.59%]</td>\n",
       "      <td>[65.93%, 71.14%]</td>\n",
       "      <td>[88.40%, 91.47%]</td>\n",
       "      <td>[99.76%, 99.89%]</td>\n",
       "      <td>[1.74%, 3.21%]</td>\n",
       "      <td>[62.16%, 64.10%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.3 Base</th>\n",
       "      <td>[53.96%, 64.51%]</td>\n",
       "      <td>[75.28%, 79.73%]</td>\n",
       "      <td>[88.29%, 91.25%]</td>\n",
       "      <td>[99.77%, 99.90%]</td>\n",
       "      <td>[1.18%, 2.40%]</td>\n",
       "      <td>[61.85%, 63.76%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-v0.3 ITI</th>\n",
       "      <td>[50.93%, 61.81%]</td>\n",
       "      <td>[47.32%, 53.25%]</td>\n",
       "      <td>[47.51%, 52.10%]</td>\n",
       "      <td>[52.56%, 57.87%]</td>\n",
       "      <td>[42.19%, 47.33%]</td>\n",
       "      <td>[41.02%, 43.29%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-v0.3 Base</th>\n",
       "      <td>[35.57%, 45.25%]</td>\n",
       "      <td>[59.49%, 62.22%]</td>\n",
       "      <td>[84.64%, 87.80%]</td>\n",
       "      <td>[99.29%, 99.71%]</td>\n",
       "      <td>[1.64%, 2.67%]</td>\n",
       "      <td>[62.08%, 63.94%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-v0.1 ITI</th>\n",
       "      <td>[48.59%, 59.71%]</td>\n",
       "      <td>[47.41%, 53.08%]</td>\n",
       "      <td>[51.69%, 56.28%]</td>\n",
       "      <td>[53.96%, 59.33%]</td>\n",
       "      <td>[40.85%, 46.42%]</td>\n",
       "      <td>[44.43%, 46.65%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-v0.1 Base</th>\n",
       "      <td>[38.41%, 47.87%]</td>\n",
       "      <td>[61.09%, 64.70%]</td>\n",
       "      <td>[89.24%, 91.97%]</td>\n",
       "      <td>[98.96%, 99.48%]</td>\n",
       "      <td>[4.35%, 6.45%]</td>\n",
       "      <td>[64.33%, 66.11%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-2.7b ITI</th>\n",
       "      <td>[42.93%, 53.80%]</td>\n",
       "      <td>[47.74%, 52.66%]</td>\n",
       "      <td>[48.91%, 54.26%]</td>\n",
       "      <td>[51.73%, 57.86%]</td>\n",
       "      <td>[42.45%, 48.31%]</td>\n",
       "      <td>[45.72%, 47.93%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-2.7b Base</th>\n",
       "      <td>[31.32%, 40.91%]</td>\n",
       "      <td>[48.67%, 52.60%]</td>\n",
       "      <td>[67.51%, 71.85%]</td>\n",
       "      <td>[86.62%, 90.39%]</td>\n",
       "      <td>[11.65%, 15.39%]</td>\n",
       "      <td>[57.56%, 59.54%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-125m ITI</th>\n",
       "      <td>[41.40%, 51.91%]</td>\n",
       "      <td>[48.96%, 50.92%]</td>\n",
       "      <td>[47.02%, 52.28%]</td>\n",
       "      <td>[50.88%, 56.67%]</td>\n",
       "      <td>[43.20%, 49.07%]</td>\n",
       "      <td>[43.35%, 45.56%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-125m Base</th>\n",
       "      <td>[33.35%, 43.67%]</td>\n",
       "      <td>[47.12%, 52.63%]</td>\n",
       "      <td>[58.10%, 62.68%]</td>\n",
       "      <td>[74.08%, 78.97%]</td>\n",
       "      <td>[22.57%, 27.46%]</td>\n",
       "      <td>[53.02%, 55.18%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-350m ITI</th>\n",
       "      <td>[43.34%, 54.37%]</td>\n",
       "      <td>[47.39%, 52.62%]</td>\n",
       "      <td>[47.12%, 53.19%]</td>\n",
       "      <td>[50.52%, 57.19%]</td>\n",
       "      <td>[43.02%, 49.66%]</td>\n",
       "      <td>[41.25%, 43.47%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-350m Base</th>\n",
       "      <td>[36.46%, 46.75%]</td>\n",
       "      <td>[49.87%, 50.91%]</td>\n",
       "      <td>[61.71%, 66.11%]</td>\n",
       "      <td>[77.95%, 82.48%]</td>\n",
       "      <td>[17.84%, 22.46%]</td>\n",
       "      <td>[54.25%, 56.44%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct ITI</th>\n",
       "      <td>[48.88%, 59.79%]</td>\n",
       "      <td>[47.43%, 53.52%]</td>\n",
       "      <td>[60.70%, 65.71%]</td>\n",
       "      <td>[66.06%, 71.62%]</td>\n",
       "      <td>[28.85%, 34.64%]</td>\n",
       "      <td>[48.45%, 50.71%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct Base</th>\n",
       "      <td>[52.46%, 63.06%]</td>\n",
       "      <td>[74.13%, 77.95%]</td>\n",
       "      <td>[81.62%, 85.20%]</td>\n",
       "      <td>[93.94%, 96.11%]</td>\n",
       "      <td>[8.91%, 11.90%]</td>\n",
       "      <td>[57.35%, 59.24%]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           par3 common_claim_true_false  \\\n",
       "Llama-2-7b-hf ITI              [46.15%, 55.95%]        [53.69%, 55.72%]   \n",
       "Llama-2-7b-hf Base             [31.50%, 40.85%]        [57.21%, 59.46%]   \n",
       "Meta-Llama-3-8B ITI            [48.43%, 59.77%]        [49.02%, 50.10%]   \n",
       "Meta-Llama-3-8B Base           [32.59%, 42.15%]        [47.98%, 53.85%]   \n",
       "Meta-Llama-3-8B-Instruct ITI   [52.83%, 63.57%]        [47.10%, 53.30%]   \n",
       "Meta-Llama-3-8B-Instruct Base  [44.61%, 54.88%]        [53.67%, 59.20%]   \n",
       "Mistral-7B-Instruct-v0.2 ITI   [55.62%, 66.20%]        [78.16%, 82.63%]   \n",
       "Mistral-7B-Instruct-v0.2 Base  [58.48%, 69.19%]        [78.53%, 83.17%]   \n",
       "Mistral-7B-Instruct-v0.3 ITI   [51.07%, 61.59%]        [65.93%, 71.14%]   \n",
       "Mistral-7B-Instruct-v0.3 Base  [53.96%, 64.51%]        [75.28%, 79.73%]   \n",
       "Mistral-7B-v0.3 ITI            [50.93%, 61.81%]        [47.32%, 53.25%]   \n",
       "Mistral-7B-v0.3 Base           [35.57%, 45.25%]        [59.49%, 62.22%]   \n",
       "Mixtral-8x7B-v0.1 ITI          [48.59%, 59.71%]        [47.41%, 53.08%]   \n",
       "Mixtral-8x7B-v0.1 Base         [38.41%, 47.87%]        [61.09%, 64.70%]   \n",
       "opt-2.7b ITI                   [42.93%, 53.80%]        [47.74%, 52.66%]   \n",
       "opt-2.7b Base                  [31.32%, 40.91%]        [48.67%, 52.60%]   \n",
       "opt-125m ITI                   [41.40%, 51.91%]        [48.96%, 50.92%]   \n",
       "opt-125m Base                  [33.35%, 43.67%]        [47.12%, 52.63%]   \n",
       "opt-350m ITI                   [43.34%, 54.37%]        [47.39%, 52.62%]   \n",
       "opt-350m Base                  [36.46%, 46.75%]        [49.87%, 50.91%]   \n",
       "Phi-3-mini-4k-instruct ITI     [48.88%, 59.79%]        [47.43%, 53.52%]   \n",
       "Phi-3-mini-4k-instruct Base    [52.46%, 63.06%]        [74.13%, 77.95%]   \n",
       "\n",
       "                              counterfact_true_false            cities  \\\n",
       "Llama-2-7b-hf ITI                   [85.50%, 88.54%]  [97.26%, 98.65%]   \n",
       "Llama-2-7b-hf Base                  [84.84%, 87.87%]  [97.96%, 99.13%]   \n",
       "Meta-Llama-3-8B ITI                 [50.53%, 55.80%]  [54.67%, 60.80%]   \n",
       "Meta-Llama-3-8B Base                [76.33%, 80.62%]  [92.99%, 95.49%]   \n",
       "Meta-Llama-3-8B-Instruct ITI        [53.76%, 58.98%]  [57.38%, 63.38%]   \n",
       "Meta-Llama-3-8B-Instruct Base       [77.66%, 81.76%]  [83.90%, 87.98%]   \n",
       "Mistral-7B-Instruct-v0.2 ITI        [84.29%, 87.75%]  [99.45%, 99.79%]   \n",
       "Mistral-7B-Instruct-v0.2 Base       [84.46%, 87.99%]  [99.51%, 99.81%]   \n",
       "Mistral-7B-Instruct-v0.3 ITI        [88.40%, 91.47%]  [99.76%, 99.89%]   \n",
       "Mistral-7B-Instruct-v0.3 Base       [88.29%, 91.25%]  [99.77%, 99.90%]   \n",
       "Mistral-7B-v0.3 ITI                 [47.51%, 52.10%]  [52.56%, 57.87%]   \n",
       "Mistral-7B-v0.3 Base                [84.64%, 87.80%]  [99.29%, 99.71%]   \n",
       "Mixtral-8x7B-v0.1 ITI               [51.69%, 56.28%]  [53.96%, 59.33%]   \n",
       "Mixtral-8x7B-v0.1 Base              [89.24%, 91.97%]  [98.96%, 99.48%]   \n",
       "opt-2.7b ITI                        [48.91%, 54.26%]  [51.73%, 57.86%]   \n",
       "opt-2.7b Base                       [67.51%, 71.85%]  [86.62%, 90.39%]   \n",
       "opt-125m ITI                        [47.02%, 52.28%]  [50.88%, 56.67%]   \n",
       "opt-125m Base                       [58.10%, 62.68%]  [74.08%, 78.97%]   \n",
       "opt-350m ITI                        [47.12%, 53.19%]  [50.52%, 57.19%]   \n",
       "opt-350m Base                       [61.71%, 66.11%]  [77.95%, 82.48%]   \n",
       "Phi-3-mini-4k-instruct ITI          [60.70%, 65.71%]  [66.06%, 71.62%]   \n",
       "Phi-3-mini-4k-instruct Base         [81.62%, 85.20%]  [93.94%, 96.11%]   \n",
       "\n",
       "                                     neg_cities       politicians  \n",
       "Llama-2-7b-hf ITI                [2.26%, 4.35%]  [60.79%, 62.71%]  \n",
       "Llama-2-7b-hf Base               [2.87%, 5.00%]  [62.00%, 63.92%]  \n",
       "Meta-Llama-3-8B ITI            [39.37%, 45.94%]  [44.58%, 46.73%]  \n",
       "Meta-Llama-3-8B Base            [8.64%, 12.12%]  [58.45%, 60.36%]  \n",
       "Meta-Llama-3-8B-Instruct ITI   [35.52%, 41.38%]  [47.14%, 49.31%]  \n",
       "Meta-Llama-3-8B-Instruct Base   [9.46%, 13.18%]  [56.93%, 58.87%]  \n",
       "Mistral-7B-Instruct-v0.2 ITI    [8.58%, 12.09%]  [58.76%, 60.73%]  \n",
       "Mistral-7B-Instruct-v0.2 Base   [7.30%, 10.47%]  [58.29%, 60.32%]  \n",
       "Mistral-7B-Instruct-v0.3 ITI     [1.74%, 3.21%]  [62.16%, 64.10%]  \n",
       "Mistral-7B-Instruct-v0.3 Base    [1.18%, 2.40%]  [61.85%, 63.76%]  \n",
       "Mistral-7B-v0.3 ITI            [42.19%, 47.33%]  [41.02%, 43.29%]  \n",
       "Mistral-7B-v0.3 Base             [1.64%, 2.67%]  [62.08%, 63.94%]  \n",
       "Mixtral-8x7B-v0.1 ITI          [40.85%, 46.42%]  [44.43%, 46.65%]  \n",
       "Mixtral-8x7B-v0.1 Base           [4.35%, 6.45%]  [64.33%, 66.11%]  \n",
       "opt-2.7b ITI                   [42.45%, 48.31%]  [45.72%, 47.93%]  \n",
       "opt-2.7b Base                  [11.65%, 15.39%]  [57.56%, 59.54%]  \n",
       "opt-125m ITI                   [43.20%, 49.07%]  [43.35%, 45.56%]  \n",
       "opt-125m Base                  [22.57%, 27.46%]  [53.02%, 55.18%]  \n",
       "opt-350m ITI                   [43.02%, 49.66%]  [41.25%, 43.47%]  \n",
       "opt-350m Base                  [17.84%, 22.46%]  [54.25%, 56.44%]  \n",
       "Phi-3-mini-4k-instruct ITI     [28.85%, 34.64%]  [48.45%, 50.71%]  \n",
       "Phi-3-mini-4k-instruct Base     [8.91%, 11.90%]  [57.35%, 59.24%]  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference on each dataset between ITI and Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      " & par3 & common_claim_true_false & counterfact_true_false & cities & neg_cities & politicians \\\\\n",
      "\\midrule\n",
      "Llama-2-7b-hf & [11.57%, 18.67%] & [-5.23%, -2.05%] & [-0.23%, 1.53%] & [-0.94%, -0.22%] & [-0.97%, -0.33%] & [-1.60%, -0.83%] \\\\\n",
      "Meta-Llama-3-8B & [10.19%, 22.75%] & [-3.87%, 1.30%] & [-28.06%, -22.99%] & [-39.46%, -33.63%] & [29.52%, 34.91%] & [-14.89%, -12.69%] \\\\\n",
      "Meta-Llama-3-8B-Instruct & [2.65%, 14.51%] & [-12.37%, -0.61%] & [-25.65%, -21.00%] & [-27.61%, -23.17%] & [24.81%, 29.64%] & [-10.76%, -8.67%] \\\\\n",
      "Mistral-7B-Instruct-v0.2 & [-4.52%, -1.76%] & [-1.27%, 0.35%] & [-0.36%, 0.08%] & [-0.09%, 0.02%] & [1.11%, 1.69%] & [0.29%, 0.64%] \\\\\n",
      "Mistral-7B-Instruct-v0.3 & [-4.62%, -1.68%] & [-10.83%, -7.24%] & [-0.02%, 0.37%] & [-0.03%, 0.03%] & [0.52%, 0.89%] & [0.22%, 0.41%] \\\\\n",
      "Mistral-7B-v0.3 & [9.34%, 21.87%] & [-14.75%, -6.46%] & [-39.08%, -33.77%] & [-47.05%, -41.69%] & [39.92%, 45.34%] & [-22.10%, -19.63%] \\\\\n",
      "Mixtral-8x7B-v0.1 & [4.63%, 17.28%] & [-17.25%, -7.98%] & [-39.01%, -34.19%] & [-45.31%, -40.01%] & [35.65%, 40.97%] & [-20.81%, -18.52%] \\\\\n",
      "opt-2.7b & [6.66%, 18.25%] & [-4.58%, 3.85%] & [-20.40%, -15.78%] & [-36.58%, -31.26%] & [29.01%, 34.32%] & [-12.74%, -10.69%] \\\\\n",
      "opt-125m & [2.77%, 13.77%] & [-3.45%, 3.85%] & [-13.06%, -8.36%] & [-25.24%, -20.15%] & [18.78%, 23.73%] & [-10.49%, -8.67%] \\\\\n",
      "opt-350m & [2.40%, 12.33%] & [-2.85%, 2.17%] & [-16.34%, -11.21%] & [-29.64%, -23.38%] & [22.97%, 29.10%] & [-14.01%, -11.95%] \\\\\n",
      "Phi-3-mini-4k-instruct & [-9.20%, 2.03%] & [-29.11%, -22.21%] & [-22.98%, -17.55%] & [-28.85%, -23.59%] & [18.87%, 23.73%] & [-9.75%, -7.45%] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc_difference_df = pd.DataFrame(columns=dataset_names)\n",
    "for m_name in model_names:\n",
    "    row = {}\n",
    "    for d_name in dataset_names:\n",
    "        file_name_ITI = f\"is_correct_{m_name}_ITI_truthful_qa_{d_name}.npz\"\n",
    "        file_name_Base = f\"is_correct_{m_name}_Base_truthful_qa_{d_name}.npz\"\n",
    "        p_ITI = np.load(os.path.join(data_dir, file_name_ITI))['is_correct']\n",
    "        p_Base = np.load(os.path.join(data_dir, file_name_Base))['is_correct']\n",
    "        row[d_name] = bootstrap_CI(p_ITI - p_Base)[0]\n",
    "    mc_difference_df.loc[f\"{m_name}\"] = row\n",
    "\n",
    "print(mc_difference_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par3</th>\n",
       "      <th>common_claim_true_false</th>\n",
       "      <th>counterfact_true_false</th>\n",
       "      <th>cities</th>\n",
       "      <th>neg_cities</th>\n",
       "      <th>politicians</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-2-7b-hf</th>\n",
       "      <td>[11.57%, 18.67%]</td>\n",
       "      <td>[-5.23%, -2.05%]</td>\n",
       "      <td>[-0.23%, 1.53%]</td>\n",
       "      <td>[-0.94%, -0.22%]</td>\n",
       "      <td>[-0.97%, -0.33%]</td>\n",
       "      <td>[-1.60%, -0.83%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B</th>\n",
       "      <td>[10.19%, 22.75%]</td>\n",
       "      <td>[-3.87%, 1.30%]</td>\n",
       "      <td>[-28.06%, -22.99%]</td>\n",
       "      <td>[-39.46%, -33.63%]</td>\n",
       "      <td>[29.52%, 34.91%]</td>\n",
       "      <td>[-14.89%, -12.69%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>[2.65%, 14.51%]</td>\n",
       "      <td>[-12.37%, -0.61%]</td>\n",
       "      <td>[-25.65%, -21.00%]</td>\n",
       "      <td>[-27.61%, -23.17%]</td>\n",
       "      <td>[24.81%, 29.64%]</td>\n",
       "      <td>[-10.76%, -8.67%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>[-4.52%, -1.76%]</td>\n",
       "      <td>[-1.27%, 0.35%]</td>\n",
       "      <td>[-0.36%, 0.08%]</td>\n",
       "      <td>[-0.09%, 0.02%]</td>\n",
       "      <td>[1.11%, 1.69%]</td>\n",
       "      <td>[0.29%, 0.64%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>[-4.62%, -1.68%]</td>\n",
       "      <td>[-10.83%, -7.24%]</td>\n",
       "      <td>[-0.02%, 0.37%]</td>\n",
       "      <td>[-0.03%, 0.03%]</td>\n",
       "      <td>[0.52%, 0.89%]</td>\n",
       "      <td>[0.22%, 0.41%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-v0.3</th>\n",
       "      <td>[9.34%, 21.87%]</td>\n",
       "      <td>[-14.75%, -6.46%]</td>\n",
       "      <td>[-39.08%, -33.77%]</td>\n",
       "      <td>[-47.05%, -41.69%]</td>\n",
       "      <td>[39.92%, 45.34%]</td>\n",
       "      <td>[-22.10%, -19.63%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-v0.1</th>\n",
       "      <td>[4.63%, 17.28%]</td>\n",
       "      <td>[-17.25%, -7.98%]</td>\n",
       "      <td>[-39.01%, -34.19%]</td>\n",
       "      <td>[-45.31%, -40.01%]</td>\n",
       "      <td>[35.65%, 40.97%]</td>\n",
       "      <td>[-20.81%, -18.52%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-2.7b</th>\n",
       "      <td>[6.66%, 18.25%]</td>\n",
       "      <td>[-4.58%, 3.85%]</td>\n",
       "      <td>[-20.40%, -15.78%]</td>\n",
       "      <td>[-36.58%, -31.26%]</td>\n",
       "      <td>[29.01%, 34.32%]</td>\n",
       "      <td>[-12.74%, -10.69%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-125m</th>\n",
       "      <td>[2.77%, 13.77%]</td>\n",
       "      <td>[-3.45%, 3.85%]</td>\n",
       "      <td>[-13.06%, -8.36%]</td>\n",
       "      <td>[-25.24%, -20.15%]</td>\n",
       "      <td>[18.78%, 23.73%]</td>\n",
       "      <td>[-10.49%, -8.67%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-350m</th>\n",
       "      <td>[2.40%, 12.33%]</td>\n",
       "      <td>[-2.85%, 2.17%]</td>\n",
       "      <td>[-16.34%, -11.21%]</td>\n",
       "      <td>[-29.64%, -23.38%]</td>\n",
       "      <td>[22.97%, 29.10%]</td>\n",
       "      <td>[-14.01%, -11.95%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>[-9.20%, 2.03%]</td>\n",
       "      <td>[-29.11%, -22.21%]</td>\n",
       "      <td>[-22.98%, -17.55%]</td>\n",
       "      <td>[-28.85%, -23.59%]</td>\n",
       "      <td>[18.87%, 23.73%]</td>\n",
       "      <td>[-9.75%, -7.45%]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      par3 common_claim_true_false  \\\n",
       "Llama-2-7b-hf             [11.57%, 18.67%]        [-5.23%, -2.05%]   \n",
       "Meta-Llama-3-8B           [10.19%, 22.75%]         [-3.87%, 1.30%]   \n",
       "Meta-Llama-3-8B-Instruct   [2.65%, 14.51%]       [-12.37%, -0.61%]   \n",
       "Mistral-7B-Instruct-v0.2  [-4.52%, -1.76%]         [-1.27%, 0.35%]   \n",
       "Mistral-7B-Instruct-v0.3  [-4.62%, -1.68%]       [-10.83%, -7.24%]   \n",
       "Mistral-7B-v0.3            [9.34%, 21.87%]       [-14.75%, -6.46%]   \n",
       "Mixtral-8x7B-v0.1          [4.63%, 17.28%]       [-17.25%, -7.98%]   \n",
       "opt-2.7b                   [6.66%, 18.25%]         [-4.58%, 3.85%]   \n",
       "opt-125m                   [2.77%, 13.77%]         [-3.45%, 3.85%]   \n",
       "opt-350m                   [2.40%, 12.33%]         [-2.85%, 2.17%]   \n",
       "Phi-3-mini-4k-instruct     [-9.20%, 2.03%]      [-29.11%, -22.21%]   \n",
       "\n",
       "                         counterfact_true_false              cities  \\\n",
       "Llama-2-7b-hf                   [-0.23%, 1.53%]    [-0.94%, -0.22%]   \n",
       "Meta-Llama-3-8B              [-28.06%, -22.99%]  [-39.46%, -33.63%]   \n",
       "Meta-Llama-3-8B-Instruct     [-25.65%, -21.00%]  [-27.61%, -23.17%]   \n",
       "Mistral-7B-Instruct-v0.2        [-0.36%, 0.08%]     [-0.09%, 0.02%]   \n",
       "Mistral-7B-Instruct-v0.3        [-0.02%, 0.37%]     [-0.03%, 0.03%]   \n",
       "Mistral-7B-v0.3              [-39.08%, -33.77%]  [-47.05%, -41.69%]   \n",
       "Mixtral-8x7B-v0.1            [-39.01%, -34.19%]  [-45.31%, -40.01%]   \n",
       "opt-2.7b                     [-20.40%, -15.78%]  [-36.58%, -31.26%]   \n",
       "opt-125m                      [-13.06%, -8.36%]  [-25.24%, -20.15%]   \n",
       "opt-350m                     [-16.34%, -11.21%]  [-29.64%, -23.38%]   \n",
       "Phi-3-mini-4k-instruct       [-22.98%, -17.55%]  [-28.85%, -23.59%]   \n",
       "\n",
       "                                neg_cities         politicians  \n",
       "Llama-2-7b-hf             [-0.97%, -0.33%]    [-1.60%, -0.83%]  \n",
       "Meta-Llama-3-8B           [29.52%, 34.91%]  [-14.89%, -12.69%]  \n",
       "Meta-Llama-3-8B-Instruct  [24.81%, 29.64%]   [-10.76%, -8.67%]  \n",
       "Mistral-7B-Instruct-v0.2    [1.11%, 1.69%]      [0.29%, 0.64%]  \n",
       "Mistral-7B-Instruct-v0.3    [0.52%, 0.89%]      [0.22%, 0.41%]  \n",
       "Mistral-7B-v0.3           [39.92%, 45.34%]  [-22.10%, -19.63%]  \n",
       "Mixtral-8x7B-v0.1         [35.65%, 40.97%]  [-20.81%, -18.52%]  \n",
       "opt-2.7b                  [29.01%, 34.32%]  [-12.74%, -10.69%]  \n",
       "opt-125m                  [18.78%, 23.73%]   [-10.49%, -8.67%]  \n",
       "opt-350m                  [22.97%, 29.10%]  [-14.01%, -11.95%]  \n",
       "Phi-3-mini-4k-instruct    [18.87%, 23.73%]    [-9.75%, -7.45%]  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_difference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI for general ITI vs general Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      " & par3 & common_claim_true_false & counterfact_true_false & cities & neg_cities & politicians \\\\\n",
      "\\midrule\n",
      "Aggregated over models & [6.20%, 9.35%] & [-7.42%, -5.27%] & [-17.36%, -16.04%] & [-24.28%, -22.75%] & [21.29%, 22.76%] & [-10.05%, -9.46%] \\\\\n",
      "Number of observations & 3017 & 10934 & 10934 & 8162 & 8162 & 74316 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc_aggregated_difference_df = pd.DataFrame(columns=dataset_names)\n",
    "row = {}\n",
    "ns = {}\n",
    "for d_name in dataset_names:\n",
    "    p_diff = []\n",
    "    for m_name in model_names:\n",
    "        file_name_ITI = f\"is_correct_{m_name}_ITI_truthful_qa_{d_name}.npz\"\n",
    "        file_name_Base = f\"is_correct_{m_name}_Base_truthful_qa_{d_name}.npz\"\n",
    "        p_ITI = np.load(os.path.join(data_dir, file_name_ITI))['is_correct']\n",
    "        p_Base = np.load(os.path.join(data_dir, file_name_Base))['is_correct']\n",
    "        p_diff.append(p_ITI - p_Base)\n",
    "    p_diff = np.hstack(p_diff)\n",
    "    assert p_diff.ndim == 1\n",
    "    row[d_name], ns[d_name] = bootstrap_CI(p_diff)\n",
    "mc_aggregated_difference_df.loc[f\"Aggregated over models\"] = row\n",
    "mc_aggregated_difference_df.loc[f\"Number of observations\"] = ns\n",
    "\n",
    "print(mc_aggregated_difference_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par3</th>\n",
       "      <th>common_claim_true_false</th>\n",
       "      <th>counterfact_true_false</th>\n",
       "      <th>cities</th>\n",
       "      <th>neg_cities</th>\n",
       "      <th>politicians</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aggregated over models</th>\n",
       "      <td>[6.20%, 9.35%]</td>\n",
       "      <td>[-7.42%, -5.27%]</td>\n",
       "      <td>[-17.36%, -16.04%]</td>\n",
       "      <td>[-24.28%, -22.75%]</td>\n",
       "      <td>[21.29%, 22.76%]</td>\n",
       "      <td>[-10.05%, -9.46%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of observations</th>\n",
       "      <td>3017</td>\n",
       "      <td>10934</td>\n",
       "      <td>10934</td>\n",
       "      <td>8162</td>\n",
       "      <td>8162</td>\n",
       "      <td>74316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  par3 common_claim_true_false  \\\n",
       "Aggregated over models  [6.20%, 9.35%]        [-7.42%, -5.27%]   \n",
       "Number of observations            3017                   10934   \n",
       "\n",
       "                       counterfact_true_false              cities  \\\n",
       "Aggregated over models     [-17.36%, -16.04%]  [-24.28%, -22.75%]   \n",
       "Number of observations                  10934                8162   \n",
       "\n",
       "                              neg_cities        politicians  \n",
       "Aggregated over models  [21.29%, 22.76%]  [-10.05%, -9.46%]  \n",
       "Number of observations              8162              74316  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_aggregated_difference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI for OOD performance of ITI vs Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.04%, -8.55%]\n",
      "112508\n"
     ]
    }
   ],
   "source": [
    "p_diff = []\n",
    "for d_name in filter(lambda x: 'par3' not in x, dataset_names):\n",
    "    for m_name in model_names:\n",
    "        file_name_ITI = f\"is_correct_{m_name}_ITI_truthful_qa_{d_name}.npz\"\n",
    "        file_name_Base = f\"is_correct_{m_name}_Base_truthful_qa_{d_name}.npz\"\n",
    "        p_ITI = np.load(os.path.join(data_dir, file_name_ITI))['is_correct']\n",
    "        p_Base = np.load(os.path.join(data_dir, file_name_Base))['is_correct']\n",
    "        p_diff.append(p_ITI - p_Base)\n",
    "\n",
    "p_diff = np.hstack(p_diff)\n",
    "assert p_diff.ndim == 1\n",
    "CI_ood_aggregated, N = bootstrap_CI(p_diff)\n",
    "\n",
    "print(CI_ood_aggregated)\n",
    "print(N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
